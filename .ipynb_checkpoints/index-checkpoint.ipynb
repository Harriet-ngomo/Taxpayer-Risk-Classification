{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxpayer Risk Classification Project\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In many countries, tax evasion and non-compliance significantly reduce government revenue needed for critical services like education, infrastructure, and healthcare. While some taxpayers follow rules diligently, others exploit system loopholes or avoid taxes altogether.\n",
    "Manual audit selection methods often depend on human judgment and limited resources, leading to inefficiencies and unfair targeting. However, by leveraging taxpayer data  such as revenue, expenses, filing behavior, and industry machine learning can help authorities flag potential high risk taxpayers more accurately. This enables smarter enforcement, early detection of risk, and a fairer tax ecosystem.\n",
    "\n",
    "---\n",
    "\n",
    "## Business Problem\n",
    "Tax authorities face significant challenges in efficiently identifying taxpayers who are at high risk of non compliance or tax evasion. Without accurate risk profiling, audits and enforcement actions may be misallocated, leading to revenue losses and wasted resources. There is a need for a data driven approach to classify taxpayers based on their risk levels, enabling focused compliance efforts.\n",
    "The challenge is to determine whether this existing taxpayer data can be used to **accurately classify taxpayers as high or low risk**, enabling smarter audit selection, reducing the burden on compliant taxpayers, and improving overall compliance.\n",
    "\n",
    "> **How can we leverage taxpayer financial and behavioral data to automatically and accurately classify taxpayers by risk level, in order to support targeted audits, enhance compliance monitoring, and increase tax revenue efficiency?**\n",
    "\n",
    "---\n",
    "\n",
    "## Stakeholders\n",
    "| Stakeholder             | Role / Interest                                                                                 |\n",
    "|------------------------|------------------------------------------------------------------------------------------------|\n",
    "| **Tax Authority / Revenue Service**| Responsible for tax collection, compliance enforcement, and overall revenue maximization.    |\n",
    "| **Audit Teams**            | Use risk classifications to prioritize audits and investigations for efficient resource use.   |\n",
    "| **Policy Makers**           | Use insights from the model to improve tax regulations and compliance strategies.               |\n",
    "| **Taxpayers**               | Subject to audits and compliance monitoring; directly impacted by classification outcomes.     |\n",
    "| **Data Analysts / Data Scientists** | Develop, validate, and maintain predictive models, providing actionable insights to stakeholders |\n",
    "\n",
    "---\n",
    "\n",
    "## Business Objectives\n",
    "1. **How can we improve audit efficiency by prioritizing audits on high-risk taxpayers to reduce costs and increase revenue recovery?**\n",
    "\n",
    "2. **How can we develop a predictive model to categorize taxpayers by risk level (Low, Medium, High) for ongoing compliance monitoring and early intervention?**\n",
    "\n",
    "3. **How can we proactively identify potential non-compliant taxpayers to reduce tax evasion and maximize government revenue?**\n",
    "\n",
    "---\n",
    "\n",
    "## Analysis Objectives\n",
    "- **How can we build and validate a machine learning classification model that accurately predicts the risk label of taxpayers based on their financial and behavioral features?**\n",
    "\n",
    "- **Which features (e.g., revenue, expenses, late filings) most significantly influence the taxpayer risk classification and how can these insights inform targeted policy actions?**\n",
    "\n",
    "---\n",
    "## Data Understanding\n",
    "\n",
    "We will use taxpayer financial and behavioral data to build a predictive model. The dataset includes records of individual and business taxpayers, featuring approximately **1000** observations and **13** columns.\n",
    "\n",
    "### Data  Description\n",
    "| Column Name          | Description                                                                                       | Data Type              |\n",
    "|----------------------|---------------------------------------------------------------------------------------------------|------------------------|\n",
    "| `Taxpayer_ID`          | Unique identifier for each taxpayer                                                               | Categorical (ID)       |\n",
    "| `Revenue`              | Total revenue reported by the taxpayer over a specific period                                     | Numeric (Continuous)   |\n",
    "| `Expenses`            | Total expenses declared by the taxpayer                                                           | Numeric (Continuous)   |\n",
    "| `Profit`              | Net profit calculated as Revenue minus Expenses                                                   | Numeric (Continuous)   |\n",
    "| `Industry_Type`        | Sector in which the taxpayer operates (e.g., Retail, Manufacturing)                              | Categorical            |\n",
    "| `Business_Age`        | Number of years the business has been operating                                                   | Numeric (Discrete)     |\n",
    "| `Late_Filings`        | Number of late tax return submissions                                                              | Numeric (Discrete)     |\n",
    "| `Audit_History`        | Count of previous audits conducted on the taxpayer                                                | Numeric (Discrete)     |\n",
    "| `Payment_Delays`       | Number of instances where tax payments were delayed                                               | Numeric (Discrete)     |\n",
    "| `Employee_Count`      | Number of employees reported by the business                                                      | Numeric (Discrete)     |\n",
    "| `Compliance_Score`     | Internal score indicating taxpayer’s level of compliance (e.g., 0–100 scale)                      | Numeric (Continuous)   |\n",
    "| `Region`               | Geographical location or jurisdiction of the taxpayer                                             | Categorical            |\n",
    "| `Risk_Label`         | Target variable: classification of the taxpayer’s compliance risk (Low, Medium, High)            | Categorical (Target)   |\n",
    "\n",
    "\n",
    "\n",
    "### Data Overview\n",
    "\n",
    "Key features in the dataset include:\n",
    "\n",
    "- **Demographics** – Taxpayer ID, age, industry, location.\n",
    "- **Financial Data** – Reported revenue, deductible expenses, net income.\n",
    "- **Behavioral Data** – Filing frequency, past audits, late submissions, and penalties.\n",
    "- **Risk Labels** – Historical classification as high, medium, or low risk (target variable).\n",
    "\n",
    "### Data Exploration Approach\n",
    "\n",
    "To extract actionable insights and ensure data quality, we will:\n",
    "\n",
    "- Load and inspect the dataset to understand its structure and feature types\n",
    "- Handle missing values through imputation or removal depending on the nature and distribution\n",
    "- Explore relationships between taxpayer behavior and risk level\n",
    "- Visualize trends, outliers, and class imbalance (if any) before modeling\n",
    "\n",
    "\n",
    "## Prediction Target\n",
    "We are predicting the **Taxpayer Risk Label**, which categorizes taxpayers into different risk levels **Low**, **Medium**, or **High** risk of non-compliance or tax evasion based on their financial data and compliance behavior. This classification helps tax authorities prioritize audits and enforcement actions effectively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score,confusion_matrix,roc_curve,auc,classification_report \n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "# Algorithms for supervised learning methods\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Harriet\\Downloads\\PHASE 3 PROJECT\\data\\tax_risk_dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA INSPECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Column names:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "print(\"\\n Data types and non-null counts:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\n Summary statistics (numerical columns):\")\n",
    "print(data.describe())\n",
    "\n",
    "print(\"\\n Preview of the first 5 rows:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\n Preview rows and columns:\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION\n",
    "\n",
    "### Checking for missing, duplicated and placeholder values.\n",
    "\n",
    "We will begin the data cleaning by checking for missing, duplicated and placeholder values in the dataset. One function will be used to check for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that returns null, duplicated and placeholder values in the dataset.\n",
    "\n",
    "def data_prep(df):\n",
    "    print('-------------------------Missing Values Check---------------------------------------\\n')\n",
    "    print(f'Number of null values in each column in the dataset:\\n{df.isnull().sum()}\\n')\n",
    "    print('-------------------------Duplicated Values Check------------------------------------\\n')\n",
    "    print(f'Number of duplicated values in the dataset: {df.duplicated().sum()}\\n')\n",
    "    print('-------------------------Placeholder Values Check-----------------------------------\\n')\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        placeholders = [value for value in unique_values if str(value).strip().lower() in ['placeholder', 'na', 'n/a', '?']]\n",
    "        placeholder_count = len(placeholders)\n",
    "    \n",
    "        print(f\"Column: '{column}'\")\n",
    "        print(f\"Placeholders found: {placeholders}\")\n",
    "        print(f\"Count of placeholders: {placeholder_count}\\n\")\n",
    "# Checking in our dataset.\n",
    "data_prep(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has no missing,duplicated or placeholder values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the dataset has any outliers and decide on whether to drop or keep them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that checks for outliers in the dataset.\n",
    "def check_outliers(df, columns):\n",
    "    for column in columns:\n",
    "        # Calculate IQR (Interquartile Range)\n",
    "        iqr = df[column].quantile(0.75) - df[column].quantile(0.25)\n",
    "        \n",
    "        # Define lower and upper thresholds\n",
    "        lower_threshold = df[column].quantile(0.25) - 1.5 * iqr\n",
    "        upper_threshold = df[column].quantile(0.75) + 1.5 * iqr\n",
    "\n",
    "        # Find outliers\n",
    "        outliers = df[(df[column] < lower_threshold) | (df[column] > upper_threshold)]\n",
    "\n",
    "        # Print the count of outliers\n",
    "        print(f\"{column}\\nNumber of outliers: {len(outliers)}\\n\")\n",
    "\n",
    "columns_to_check = data.select_dtypes(include = ['number'])\n",
    "check_outliers(data, columns_to_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has a few outliers so let's try to visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a boxplot to check for outliers\n",
    "features_to_plot = data.select_dtypes(include = ['number'])\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=features_to_plot, ax=plt.gca())\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Boxplot of Numeric Columns')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose to retain them rather than drop them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling the Target Variable (`Risk_Label`)\n",
    "\n",
    "- For binary classification let's filter the dataset to keep only the rows where the `Risk_Label` is either **\"Low\"** or **\"High\"**\n",
    "- This ensures that only relevant classes are included in the analysis\n",
    "  \n",
    "- Let's manually map the categorical labels to numeric values:\n",
    "  - `\"Low\"` is mapped to `0`\n",
    "  - `\"High\"` is mapped to `1`\n",
    "\n",
    "This numeric encoding is necessary for most machine learning algorithms that require numerical inputs, and mapping `\"High\"` to `1` clearly indicates it as the positive/high-risk class in the classification problem\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"Risk_Label\"].isin([\"Low\", \"High\"])]\n",
    "data[\"Risk_Label\"] = data[\"Risk_Label\"].map({\"Low\": 0, \"High\": 1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now do a value count of the Risk Label column to see if the rows have 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Risk_Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display value counts of unique items\n",
    "print(data['Risk_Label'].value_counts())\n",
    "\n",
    "# Set custom font parameters\n",
    "sns.set(font_scale=1.5)\n",
    "colors = sns.color_palette(\"Set1\")\n",
    "# Create a countplot of the 'Risk label' feature\n",
    "plt.figure(figsize=(8, 6))  \n",
    "sns.countplot(x='Risk_Label', data=data, palette=colors)\n",
    "plt.title(\"Risk_Label Count\")\n",
    "plt.xlabel(\"Risk_Label\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class frequency of target variable \n",
    "print(data['Risk_Label'].value_counts())\n",
    "print()\n",
    "print(data['Risk_Label'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's use a pie chart to visualize the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pie chart to visualize the Risk label\n",
    "risk_counts = data['Risk_Label'].value_counts()\n",
    "import seaborn as sns\n",
    "colors = sns.color_palette('tab10', n_colors=len(risk_counts))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pie(risk_counts, \n",
    "        labels=risk_counts.index, \n",
    "        autopct='%1.1f%%', \n",
    "        startangle=90, \n",
    "        colors= colors)\n",
    "plt.title('Distribution of Taxpayer Risk Levels')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The target variable, Risk_Label, is imbalanced with 82.9% high risk (1) and 17.1% low risk (0) taxpayers. \n",
    "- This imbalance can cause models to favor the majority class, so we will use SMOTE technique  and appropriate evaluation metrics to correct the imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(numerical_cols)\n",
    "print()\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing  the distribution the categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(data=data, x=col, order=data[col].value_counts().index, palette='Set2')\n",
    "    plt.title(f\"Count Plot of {col}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation matrix for all the Numeric columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric features from your dataset\n",
    "numeric_features = numerical_cols\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = data[numeric_features].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix,\n",
    "            annot=True,\n",
    "            cmap=\"coolwarm\",\n",
    "            square=True,\n",
    "            fmt=\".2f\",\n",
    "            annot_kws={\"size\": 10})\n",
    "plt.title(\"Correlation Heatmap of Financial and Compliance Variables\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTIVE MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = data.drop(columns=['Taxpayer_ID', 'Risk_Label'])\n",
    "y = data['Risk_Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dropped Taxpayer_ID because it is a unique identifier for each individual and does not provide any predictive value for determining risk level. Including it in the model could lead to overfitting or noise, as it simply identifies a record rather than describing any meaningful behavior or financial attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create training and test sets\n",
    "SEED = 42\n",
    "X_train,X_test,y_train,y_test =train_test_split(X,y,test_size=0.3,random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape ,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical data as numbers\n",
    "\n",
    "Since all of our data  has some  categorical columns , we need to encode them as numbers using sklearn's `preprocessing` module  `OneHotEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features explicitly based on your columns\n",
    "numeric_features = ['Revenue', 'Expenses', 'Tax_Liability', 'Tax_Paid', 'Late_Filings',\n",
    "                    'Compliance_Violations', 'Profit', 'Tax_Compliance_Ratio', 'Audit_Findings', 'Audit_to_Tax_Ratio']\n",
    "\n",
    "categorical_features = ['Industry']  \n",
    "\n",
    "\n",
    "# One-hot encode categorical features in X_train\n",
    "ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "X_train_ohe = ohe.fit_transform(X_train[categorical_features])\n",
    "ohe_df = pd.DataFrame(X_train_ohe, columns=ohe.get_feature_names(categorical_features), index=X_train.index)\n",
    "\n",
    "# Scale numeric features in X_train\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train[numeric_features])\n",
    "num_df = pd.DataFrame(X_train_num_scaled, columns=numeric_features, index=X_train.index)\n",
    "\n",
    "# Combine numeric and categorical features for X_train\n",
    "X_train_processed = pd.concat([num_df, ohe_df], axis=1)\n",
    "\n",
    "# Show resulting DataFrame after preprocessing\n",
    "X_train_processed.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying SMOTE after preprocessing to balance training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE after preprocessing to balance training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_processed, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the class distribution before and after applying SMOTE to see if the data is balanced after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check class distribution before and after\n",
    "from collections import Counter\n",
    "print(\"Before SMOTE:\", Counter(y_train))\n",
    "print(\"After SMOTE:\", Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Preprocess X_test using fitted transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess X_test using fitted transformers\n",
    "X_test_ohe = ohe.transform(X_test[categorical_features])\n",
    "\n",
    "# Create DataFrame with proper column names for X_test\n",
    "ohe_test_df = pd.DataFrame(X_test_ohe, columns=ohe.get_feature_names(categorical_features), index=X_test.index)\n",
    "\n",
    "# Scale numeric features in X_test using the fitted scaler\n",
    "X_test_num_scaled = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "# Convert scaled numeric features back to DataFrame\n",
    "num_test_df = pd.DataFrame(X_test_num_scaled, columns=numeric_features, index=X_test.index)\n",
    "\n",
    "# Combine scaled numeric features and one-hot encoded categorical features for X_test\n",
    "X_test_processed = pd.concat([num_test_df, ohe_test_df], axis=1)\n",
    "# Show resulting DataFrame after preprocessing X_test\n",
    "X_test_processed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 1:LOGISTIC MODEL(Baseline model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the test data using your preprocessed X_test\n",
    "y_pred = logreg.predict(X_test_processed)\n",
    "\n",
    "# Calculate accuracy\n",
    "print('Logistic Regression Accuracy:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display confusion matrix with labels from your classifier classes_\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=logreg.classes_)\n",
    "\n",
    "# Plot with customizations\n",
    "fig, ax = plt.subplots()\n",
    "disp.plot(cmap=plt.cm.coolwarm, ax=ax)\n",
    "ax.grid(False) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression Classification Report\\n\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute ROC & AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc and auc\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(y_test,y_pred)\n",
    "log_roc_auc = auc(fpr,tpr)\n",
    "print(\"Logistic roc_auc:\",log_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "lw =2\n",
    "plt.plot(fpr, tpr, label=f'Logistic regression (log_AUC = {log_roc_auc:.2f})',color =\"maroon\")\n",
    "plt.plot([0, 1], [0, 1],lw =lw,ls ='--',color =\"Blue\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 2:UNTUNED DECISION TREE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the classifier and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier, fit it on the training data and make predictions on the test set\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state =SEED)\n",
    "clf.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred_1=clf.predict(X_test_processed)\n",
    "\n",
    "# Calculate accuracy\n",
    "print('Untuned_tree_Accuracy:', accuracy_score(y_test, y_pred_1))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_1)\n",
    "\n",
    "# Display confusion matrix with labels from your classifier classes_\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "\n",
    "# Plot with customizations\n",
    "fig, ax = plt.subplots()\n",
    "disp.plot(cmap=plt.cm.coolwarm, ax=ax)\n",
    "ax.grid(False) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Untuned Decision tree Classification Report\\n\\n\", classification_report(y_test, y_pred_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc and auc\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(y_test,y_pred_1)\n",
    "tree_roc_auc = auc(fpr,tpr)\n",
    "print(tree_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "lw =2\n",
    "plt.plot(fpr, tpr, label=f'Untuned Decision Tree (Tree_AUC = {tree_roc_auc:.2f})',color =\"maroon\")\n",
    "plt.plot([0, 1], [0, 1],lw =lw,ls ='--',color =\"Blue\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the decision tree\n",
    "Let's see what rules the tree learned by plotting this decision tree, using matplotlib and sklearn's plot_tree function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1,ncols = 1, figsize = (3,3), dpi=300)\n",
    "tree.plot_tree(clf,\n",
    "          feature_names = X_train_smote.columns,\n",
    "          class_names=np.unique(y).astype('str'),\n",
    "          filled = True)\n",
    "plt.show()\n",
    "print(\"Tree depth:\", clf.get_depth())\n",
    "print(\"Number of leaves:\", clf.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hhh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hhhh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
